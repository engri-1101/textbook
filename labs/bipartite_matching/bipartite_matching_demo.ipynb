{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from networkx.algorithms import bipartite\n",
    "import networkx as nx\n",
    "from ortools.linear_solver import pywraplp as OR\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import copy\n",
    "import pickle\n",
    "from bokeh import palettes\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.tile_providers import get_provider, Vendors\n",
    "from bokeh.models import (GraphRenderer, Circle, MultiLine, StaticLayoutProvider,\n",
    "                          HoverTool, TapTool, EdgesAndLinkedNodes, NodesAndLinkedEdges,\n",
    "                          ColumnDataSource, LabelSet, NodesOnly)\n",
    "from bipartite_matching import *\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrospective Minimum Fleet-size Problem to Bipartite Matching Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a minimum fleet-size problem over some time horizon. Over this time period, we know all the ride requests we will receive. Each ride request has a start/end location, start time, and duration. A retrospective management question is to find the minimum number of vehicles needed to cover all the rides. How can we create a bipartite matching formulation to solve this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the taxi trips information as well as NYC street nodes and arcs.\n",
    "trips_df = pd.read_csv('data/2013-09-01_trip_data_manhattan.csv').drop(columns='id')\n",
    "nodes_df = pd.read_csv('data/nyc_nodes_manhattan.csv').drop(columns='Unnamed: 0')\n",
    "arcs_df = pd.read_csv('data/nyc_links_manhattan.csv').drop(columns='Unnamed: 0')\n",
    "# Load travel time matrix\n",
    "times_df = pd.read_csv('data/times.csv', index_col =0)\n",
    "times_df.columns = times_df.columns.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of 10 example trip_ids\n",
    "ex_trips = [68326, 69501, 70802, 68619, 69802, 70142, 68751, 69558, 70296, 68272]\n",
    "\n",
    "# Locate the corresponding trip information\n",
    "trips = trips_df.iloc[ex_trips]\n",
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize nodes and edges\n",
    "DO_nodes = list()\n",
    "PU_nodes = list()\n",
    "edges = list()\n",
    "# Initialize a dict that maps a PU node to a DO node\n",
    "PUtoDO = dict()\n",
    "# Construct nodes and edges\n",
    "for index, row in trips.iterrows():\n",
    "    s = row['start_node']\n",
    "    t = row['end_node']\n",
    "    s_t = row['start_time']\n",
    "    t_t = s_t + row['trip_time']\n",
    "    DO_node = (int(t), t_t, index, 'DO')\n",
    "    PU_node = (int(s), s_t, index, 'PU')\n",
    "    DO_nodes.append(DO_node)\n",
    "    PU_nodes.append(PU_node)\n",
    "    PUtoDO[PU_node] = DO_node\n",
    "# Sort the nodes by time\n",
    "DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "\n",
    "# Specify the edges\n",
    "max_waiting_time = 10 # delta\n",
    "\n",
    "for DO_node in DO_nodes:\n",
    "    for PU_node in PU_nodes:\n",
    "        if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "            break\n",
    "        else:\n",
    "            if PU_node[1] >= DO_node[1]:\n",
    "                time = times_df.at[(DO_node[0], PU_node[0])]\n",
    "                if ((PU_node[1] - DO_node[1]) - max_waiting_time  <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                    edges.append((DO_node, PU_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the bipartite graph\n",
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "B.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = nx.bipartite.maximum_matching(B, DO_nodes)\n",
    "print('Size of max cardinality matching:', int(len(match)/2)) # divided by two because the output edges are directed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace optimal taxi trajetory\n",
    "opt_paths = match_to_path(match, trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bipartite graph\n",
    "plot_ex_bipartite(B, match, opt_paths, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bipartite graph\n",
    "G = street_network(nodes_df, arcs_df, weight = 'trip_time')\n",
    "plot_bipartite_graph2(B, match, opt_paths, G, nodes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 4 taxis are needed to serve all 10 trips (shown as dotted lines above) according to our matching obtained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corresponding taxi paths on the map\n",
    "plot_taxi_route(G, opt_paths, nodes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matching with infinite allowable waiting time\n",
    "## show pairwise incompatible trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, simply change the maximum allowable waiting time to infinity; that is, we assume that drivers can wait at the new pickup location forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize nodes and edges\n",
    "DO_nodes = list()\n",
    "PU_nodes = list()\n",
    "edges = list()\n",
    "# Initialize a dict that maps a PU node to a DO node\n",
    "PUtoDO = dict()\n",
    "# Construct nodes and edges\n",
    "for index, row in trips.iterrows():\n",
    "    s = row['start_node']\n",
    "    t = row['end_node']\n",
    "    s_t = row['start_time']\n",
    "    t_t = s_t + row['trip_time']\n",
    "    DO_node = (int(t), t_t, index, 'DO')\n",
    "    PU_node = (int(s), s_t, index, 'PU')\n",
    "    DO_nodes.append(DO_node)\n",
    "    PU_nodes.append(PU_node)\n",
    "    PUtoDO[PU_node] = DO_node\n",
    "# Sort the nodes by time\n",
    "DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "\n",
    "# Specify the edges\n",
    "max_waiting_time = np.inf # delta\n",
    "\n",
    "for DO_node in DO_nodes:\n",
    "    for PU_node in PU_nodes:\n",
    "        if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "            break\n",
    "        else:\n",
    "            if PU_node[1] >= DO_node[1]:\n",
    "                time = times_df.at[(DO_node[0], PU_node[0])]\n",
    "                if ((PU_node[1] - DO_node[1]) - max_waiting_time  <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                    edges.append((DO_node, PU_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the bipartite graph\n",
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "B.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = nx.bipartite.maximum_matching(B, DO_nodes)\n",
    "print('Size of max cardinality matching:', int(len(match)/2)) # divided by two because the output edges are directed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace optimal taxi trajetory\n",
    "opt_paths = match_to_path(match, trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bipartite graph\n",
    "plot_ex_bipartite(B, match, opt_paths, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bipartite_graph2(B, match, opt_paths, G, nodes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the size of the max cardinality matching is unchanged, though the number of edges on the bipartite graph has increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corresponding taxi paths on the map\n",
    "G = street_network(nodes_df, arcs_df, weight = 'trip_time')\n",
    "plot_taxi_route(G, opt_paths, nodes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Incompatible Trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any two trips $N_i = (p_i, T^p_{i}, d_i, T^d_{i})$ and $N_j = (p_j, T^p_{j}, d_j, T^d_{j})$ are considered *compatible* with each other if a vehicle can feasibly cover both, either by reaching from $d_i$ to $p_j$ or from $d_j$ to $p_i$ in time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Theorem:* The maximum size of a set of trips that are pairwise incompatible is equal to the minimum number of vehicles needed to cover all of the trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the set of pairwise incompatible trips\n",
    "incomp_trips = [68272, 68326,  68619, 68751]\n",
    "plot_pairwise_incompatible(B, match, opt_paths, G, nodes_df, incomp_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the theorem, the maximum size of a set of pairwise incompatible trips should be equal to the minimum number of vehicles needed to cover all the trips, which is 4.  \n",
    "\n",
    "In the plot above, the set of pairwise incompatible trips are highlighted in red. Notice that this is the maximum set we could possibly find since we cannot find a larger set such that every pair of trips in the set is incompatible of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrospective Minimum Fleet-size Problem At Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, filter the trips by time window of interest. The following example selects all the trips from 5 pm to 5:30 pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter trips by time window of interest\n",
    "start_time = 1020\n",
    "end_time = 1050\n",
    "trips = trips_df.copy()\n",
    "trips = trips[(trips.start_time >= start_time) & \n",
    "              (trips.start_time + trips.trip_time <= end_time)].copy()\n",
    "trips.start_time = trips.start_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize nodes and edges\n",
    "DO_nodes = list()\n",
    "PU_nodes = list()\n",
    "edges = list()\n",
    "# Initialize a dict that maps a PU node to a DO node\n",
    "PUtoDO = dict()\n",
    "# Specify nodes - each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")\n",
    "for index, row in trips.iterrows():\n",
    "    s = row['start_node']\n",
    "    t = row['end_node']\n",
    "    s_t = row['start_time']\n",
    "    t_t = s_t + row['trip_time']\n",
    "    DO_node = (int(t), t_t, index, 'DO')\n",
    "    PU_node = (int(s), s_t, index, 'PU')\n",
    "    DO_nodes.append(DO_node)\n",
    "    PU_nodes.append(PU_node)\n",
    "    PUtoDO[PU_node] = DO_node\n",
    "# Sort the nodes by time\n",
    "DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "\n",
    "# Specify edges\n",
    "max_waiting_time = 10\n",
    "\n",
    "for DO_node in DO_nodes:\n",
    "    for PU_node in PU_nodes:\n",
    "        if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "            break\n",
    "        else:\n",
    "            if PU_node[1] >= DO_node[1]:\n",
    "                time = times_df.at[(DO_node[0], PU_node[0])]\n",
    "                if ((PU_node[1] - DO_node[1]) - max_waiting_time  <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "#                     if (PU_node[0] not in list(nx.isolates(G))) and (DO_node[0] not in list(nx.isolates(G))):\n",
    "                        edges.append((DO_node, PU_node))\n",
    "# load the model\n",
    "B2 = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B2.add_nodes_from(DO_nodes, bipartite=0)\n",
    "B2.add_nodes_from(PU_nodes, bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "B2.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match2 = nx.bipartite.maximum_matching(B2, DO_nodes)\n",
    "print('size of max cardinality matching:', len(match2) / 2)\n",
    "print('total number of trips:', len(DO_nodes))\n",
    "num_taxi = len(DO_nodes) - len(match2)/2\n",
    "print('min number of taxis needed to cover all trips:', num_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace optimal taxi trajetory\n",
    "opt_paths2 = match_to_path(match2, trips)\n",
    "# Plot the first 10 taxi paths on the map\n",
    "G = street_network(nodes_df, arcs_df, 'trip_time')\n",
    "plot_taxi_route(G, opt_paths2[:10], nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
