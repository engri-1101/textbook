{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from networkx.algorithms import bipartite\n",
    "import networkx as nx\n",
    "from ortools.linear_solver import pywraplp as OR\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "import copy\n",
    "import pickle\n",
    "from bokeh import palettes\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import (GraphRenderer, Circle, MultiLine, StaticLayoutProvider,\n",
    "                          HoverTool, TapTool, EdgesAndLinkedNodes, NodesAndLinkedEdges,\n",
    "                          ColumnDataSource, LabelSet, NodesOnly)\n",
    "from bipartite_matching import *\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Routing Bipartite Matching Lab\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* Construct the taxi-routing problem as a bipartite graph.\n",
    "* Use the maximum cardinality matching problem to solve the taxi-routing problem.\n",
    "* Compare the optimal solution to the taxi-routing problem with the original routing.\n",
    "    \n",
    "<font color='red'> **Instructor Comments** </font>\n",
    "\n",
    "<font color='blue'> **Solutions** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Bipartite Graph Formulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the taxi trips information as well as NYC street nodes and arcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.read_csv('data/2013-09-01_trip_data_manhattan.csv').drop(columns='id')\n",
    "nodes_df = pd.read_csv('data/nyc_nodes_manhattan.csv').drop(columns='Unnamed: 0')\n",
    "arcs_df = pd.read_csv('data/nyc_links_manhattan.csv').drop(columns='Unnamed: 0')\n",
    "times_df = pd.read_csv('data/times.csv', index_col =0)\n",
    "times_df.columns = times_df.columns.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at an example input. Each trip consists of the unique vehicle id (medallion), location id of the pickup node and drop-off node, pickup time and drop-off time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of example trip_ids\n",
    "ex_trips = [68326, 69501, 70802, 68619, 69802, 70142, 68751, 69558, 70296, 68272]\n",
    "# Locate the corresponding trip information\n",
    "trips = trips_df.iloc[ex_trips]\n",
    "trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a bipartite graph $G = (D, P, E)$ where $D$ and $P$ are disjoint sets corresponding to the \"left\" and \"right\" sides of the graph, and $E$ is the set of edges, each of which has exactly one endpoint in $D$ and one endpoint in $P$.\n",
    "\n",
    "Let $D = \\{(d_1, T^d_{1}),(d_2, T^d_{2}),\\ldots,(d_n, T^d_{n})\\}$ denote the set of drop-off nodes, $P = \\{(p_1, T^p_{1}),(p_2, T^p_{2}),\\ldots,(p_n, T^p_{n})\\}$ denote the set of pickup nodes, where there are $n$ taxi trips to be covered. We can express the set of taxi trips $N = \\{(p_i, T^p_{i}, d_i, T^d_{i}): i\\in \\{1,\\ldots,n\\}\\}$; that is, the taxi history shows that the $i$th trip picks up a passenger at time $T^p_{i}$ at point $p_i$ and drops off the fare at time $T^d_{i}$ at point $d_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct nodes and edges for the bipartite graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize nodes and edges\n",
    "DO_nodes = list()\n",
    "PU_nodes = list()\n",
    "edges = list()\n",
    "# Initialize a dict that maps a PU node to a DO node\n",
    "PUtoDO = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in trips.iterrows():\n",
    "    s = row['start_node']\n",
    "    t = row['end_node']\n",
    "    s_t = row['start_time']\n",
    "    t_t = s_t + row['trip_time']\n",
    "    DO_node = (int(t), t_t, index, 'DO')\n",
    "    PU_node = (int(s), s_t, index, 'PU')\n",
    "    DO_nodes.append(DO_node)\n",
    "    PU_nodes.append(PU_node)\n",
    "    PUtoDO[PU_node] = DO_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Assume that a taxi handles two consecutive trips $i$ and $j$ (in order), where the drop-off time at location $d_i$ is $T^d_i$ and the pickup time at location $p_j$ is $T^p_j$. What is the *elapsed time* between the drop-off time of trip $i$ and the pickup time of trip $j$ (express in terms of $T^d_i$ and $T^p_j$) ?\n",
    "\n",
    "**A:** <font color='blue'> The *elapsed time* is $T^p_j - T^d_i$.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Assume that $time(d_i, p_j)$ is the time needed to travel between location point $d_i$ and location point $p_j$. What relationship must hold between the *elasped time* between the drop-off time of trip $i$ and the pickup time of trip $j$ and $time(d_i, p_j)$ in order for a taxi to cover both trip $i$ and trip $j$ (express in terms of $time(d_i, p_j), T^d_i$ and $T^p_j$)? What does this inequality mean?\n",
    "\n",
    "**A:** <font color='blue'> $time(d_i, p_j) \\leq T^p_j - T^d_i$. It means that a taxi can reach the new pickup at $p_j$ in time after dropping off the fare at $d_i$. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** In the previous question, what if the taxi can only stay for a maximum of $\\delta$ minutes? What is the new inequality and what does it mean?\n",
    "\n",
    "**A:** <font color='blue'> $T^p_j - T^d_i - \\delta \\leq time(d_i, p_j) \\leq T^p_j - T^d_i$. The new inequality means that a taxi can reach the new pickup at $p_j$ in time after dropping off the fare at $d_i$, and also doesnâ€™t need to wait more than $\\delta$ minutes for the new pickup to be ready. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Based on the new inequality you just estabilished, can you define the set $E$ mathematically?\n",
    "\n",
    "**A:** <font color='blue'> $$E = \\{\\{(d_i, T^d_{i}),(p_j, T^p_{j})\\}: T^p_{j} - T^d_{i}-\\delta \\leq time(d_i, p_j) \\leq T^p_{j} - T^d_{i}\\}$$ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the nodes by time\n",
    "DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "\n",
    "# Specify the edges\n",
    "max_waiting_time = 10 # delta\n",
    "\n",
    "for DO_node in DO_nodes:\n",
    "    for PU_node in PU_nodes:\n",
    "        if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "            break\n",
    "        else:\n",
    "            if PU_node[1] >= DO_node[1]:\n",
    "                time = times_df.at[(DO_node[0], PU_node[0])]\n",
    "                if ((PU_node[1] - DO_node[1]) - max_waiting_time  <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                    edges.append((DO_node, PU_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "B.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**\n",
    "\n",
    "If a maximum cardinality matching is of size $m$, then the minimum number of taxis needed to cover all $n$ trips is $n-m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = nx.bipartite.maximum_matching(B, DO_nodes)\n",
    "print('Size of max cardinality matching:', int(len(match)/2)) # divided by two because the output edges are directed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What is the minimum number of taxis needed to cover all the trips according to the size of the maximum cardinality matching?\n",
    "\n",
    "**A:** <font color='blue'> 4 taxis.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the information given by maximum cardinality matching to track down the optimal taxi trajectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_paths = match_to_path(match, trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ex_bipartite(B, match, opt_paths, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Interpret one optimal taxi trajectory that contains three trips based on the graph above using the location ids (remember each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")).\n",
    "\n",
    "**A:** <font color='blue'> 1447->1762->1163->24->79->931 (or 2119->275->1494->1809->20->1323)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the corresponding taxi paths on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = street_network(nodes_df, arcs_df, weight = 'trip_time')\n",
    "plot_taxi_route(G, opt_paths, nodes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bipartite Graph Formulation (At Scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of selecting a sample selection of taxi trips, try filter the trips by time window of interest. The following example selects all the trips from 5 pm to 5:15 pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter trips by time window of interest\n",
    "start_time = 1020\n",
    "end_time = 1035\n",
    "trips = trips_df.copy()\n",
    "trips = trips[(trips.start_time >= start_time) & \n",
    "              (trips.start_time + trips.trip_time <= end_time)].copy()\n",
    "trips.start_time = trips.start_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes and edges are defined similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize nodes and edges\n",
    "DO_nodes = list()\n",
    "PU_nodes = list()\n",
    "edges = list()\n",
    "# Initialize a dict that maps a PU node to a DO node\n",
    "PUtoDO = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify nodes - each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")\n",
    "for index, row in trips.iterrows():\n",
    "    s = row['start_node']\n",
    "    t = row['end_node']\n",
    "    s_t = row['start_time']\n",
    "    t_t = s_t + row['trip_time']\n",
    "    DO_node = (int(t), t_t, index, 'DO')\n",
    "    PU_node = (int(s), s_t, index, 'PU')\n",
    "    DO_nodes.append(DO_node)\n",
    "    PU_nodes.append(PU_node)\n",
    "    PUtoDO[PU_node] = DO_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the nodes by time\n",
    "DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "\n",
    "# Specify edges\n",
    "max_waiting_time = 10\n",
    "\n",
    "for DO_node in DO_nodes:\n",
    "    for PU_node in PU_nodes:\n",
    "        if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "            break\n",
    "        else:\n",
    "            if PU_node[1] >= DO_node[1]:\n",
    "                time = times_df.at[(DO_node[0], PU_node[0])]\n",
    "                if ((PU_node[1] - DO_node[1]) - max_waiting_time  <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                    edges.append((DO_node, PU_node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "# Add edges only between nodes of opposite node sets\n",
    "B.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = nx.bipartite.maximum_matching(B, DO_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('size of max cardinality matching:', len(match) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of unmatched nodes (minimum number of taxis needed)\n",
    "# TODO: Set num_taxi equal to the number of unmatched nodes in terms of the number of drop-off nodes and the size of the matching\n",
    "# num_taxi = XXX\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "num_taxi = len(DO_nodes) - len(match)/2\n",
    "### END SOLUTION\n",
    "\n",
    "print('min number of taxis needed: ', num_taxi)"
   ]
  },
  {
   "source": [
    "We will write the bipartite matching problem in a format that we will use extensively as this course proceeds, which we will generally call to be Integer Programming formulations.\n",
    "\n",
    "Restating the bipartite matching problem, we are given a bipartite graph $G=(N,E)$ (which is undirected) with a node set $N= P \\cup D$ (for the pickups and drop-offs), where each edge $\\{i,j\\} \\in E$ has one endpoint $i \\in P$ and the other endpoint $j \\in D$. We wish to select a subset of edges $M \\subseteq E$ with the property that each node in $N$ is an endpoint of at most one edge in $M$; such a subset of edges is called a matching. The bipartite matching problem is, given such an input, to find the matching with maximum number of edges.\n",
    "\n",
    "We can think about writing down a matching $M$ in the following way â€“ for each edge $e \\in E$, we indicate \"yes\" or \"no\", whether or not to include $e$ in $M$. We can specify this answer by having a so-called \"decision variable\" $x(e)$ for each edge $e \\in E$, and then indicating whether that variable should be set to 1 (meaning \"yes\") or to 0 (meaning \"no\"). \n",
    "\n",
    "But given a sequence of \"yes\"s and \"no\"s, how do we know that the selected set of edges actually does correspond to a matching? We need to check that for each node, we have selected at most one edge with that endpoint. We introduce a bit of notation to help: let \n",
    "$$ \\delta (v) = \\{ e = \\{v,w\\} : \\{v,w\\} \\in E \\}; $$\n",
    "that is, $\\delta (v)$ is the set of *all* edges in $E$ that have node $v$ as one of its endpoints. For $M$ to be a matching, we need to select at most one edge in $\\delta (v)$ to be in $M$, *for each* $v \\in N = P \\cup D$. \n",
    "\n",
    "If we think about how we used the values 0 and 1 for each edge $e \\in E$, to set $x(e)$, that means that, for each $v \\in N = P \\cup D$, we have at most one $x(e )$  set to 1, and the rest are set to 0. Equivalently, we can say that we must have the sum of these variables be at most 1; that is $\\sum_{e \\in \\delta (v)} x(e ) \\leq 1$.\n",
    "Our goal is to find a matching that has as many edges as possible, and so we want $\\sum_{e \\in E} x (e )$ to be as big as possible. So this means that we can think of the bipartite matching problem as the following concisely written optimization problem:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "\\max \\quad & \\sum_{e \\in E}x_e \\\\\n",
    "\\text{s.t.} \\quad &  \\sum_{e \\in \\delta(v)} x_e \\leq 1 \\quad \\forall v \\in P \\cup D & (1)\\\\\n",
    "\\quad & x_e \\in \\{0,1\\} \\quad \\forall e \\in E & (2)\\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary that stores the list of edges adjacent to node\n",
    "incident = dict()\n",
    "for v in (DO_nodes + PU_nodes):\n",
    "    incident[v] = [edge for edge in edges if v in edge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = OR.Solver('taxi_bipartite', OR.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n",
    "# Decision variables\n",
    "x = {}  \n",
    "for e in B.edges:\n",
    "    x[e] = solver.IntVar(0, 1, ('(%s)' % str(e)))\n",
    "\n",
    "solver.Maximize(sum(x[e] for e in edges))\n",
    "\n",
    "for v in (DO_nodes + PU_nodes):\n",
    "    if v in incident.keys():\n",
    "        solver.Add(sum(x[e] for e in incident[v]) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.Solve()\n",
    "print('Solution:')\n",
    "print('Objective value =', solver.Objective().Value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check our answer by reducing the max matching problem to a max flow problem - the max flow value should be equal to the size of max cardinality matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(PU_nodes + DO_nodes + ['s'] + ['t'])\n",
    "for edge in edges:\n",
    "    G.add_edge(edge[0], edge[1], capacity = 1)\n",
    "for DO_node in DO_nodes:\n",
    "    G.add_edge('s', DO_node, capacity = 1)\n",
    "for PU_node in PU_nodes:\n",
    "    G.add_edge(PU_node, 't', capacity = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_value, flow_dict = nx.maximum_flow(G, \"s\", \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max flow value: ', flow_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another alogrithm to solve max flow\n",
    "from networkx.algorithms.flow import shortest_augmenting_path\n",
    "print('max flow value: ', nx.maximum_flow(G, \"s\", \"t\", flow_func=shortest_augmenting_path)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn the process of building a bipartite graph and solving the max cardinality matching into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_match(start_time, end_time, trips_df, max_waiting_time):\n",
    "    # filter trips by time window of interest\n",
    "    trips = trips_df.copy()\n",
    "    trips = trips[(trips.start_time >= start_time) & \n",
    "                  (trips.start_time + trips.trip_time <= end_time)].copy()\n",
    "    trips.start_time = trips.start_time - start_time\n",
    "\n",
    "    # create a dictionary to map the location pairs to trip time\n",
    "    loc_time = dict()\n",
    "    for index, row in arcs_df.iterrows():\n",
    "        i = row['start']\n",
    "        j = row['end']\n",
    "        delay = row['trip_time']\n",
    "        loc_time[(i, j)] = delay\n",
    "    # Intialize nodes and edges\n",
    "    DO_nodes = list()\n",
    "    PU_nodes = list()\n",
    "    edges = list()\n",
    "    # Initialize a dict that maps a PU node to a DO node\n",
    "    PUtoDO = dict()\n",
    "    # Specify nodes - each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")\n",
    "    for index, row in trips.iterrows():\n",
    "        s = row['start_node']\n",
    "        t = row['end_node']\n",
    "        s_t = row['start_time']\n",
    "        t_t = s_t + row['trip_time']\n",
    "        DO_node = (int(t), t_t, index, 'DO')\n",
    "        PU_node = (int(s), s_t, index, 'PU')\n",
    "        DO_nodes.append(DO_node)\n",
    "        PU_nodes.append(PU_node)\n",
    "        PUtoDO[PU_node] = DO_node\n",
    "    DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "    PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "    \n",
    "    # Specify edges\n",
    "    for DO_node in DO_nodes:\n",
    "        for PU_node in PU_nodes:\n",
    "            if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "                break\n",
    "            else:\n",
    "                if PU_node[1] >= DO_node[1]:\n",
    "                    time = times_df.at[(DO_node[0], PU_node[0])]\n",
    "                    if ((PU_node[1] - DO_node[1]) - max_waiting_time <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                        edges.append((DO_node, PU_node))\n",
    "    \n",
    "    # load the model\n",
    "    B = nx.Graph()\n",
    "    # Add nodes with the node attribute \"bipartite\"\n",
    "    B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "    B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "    # Add edges only between nodes of opposite node sets\n",
    "    B.add_edges_from(edges)\n",
    "    \n",
    "    top_nodes = {n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "    match = nx.bipartite.maximum_matching(B, top_nodes)\n",
    "    num_taxi = len(DO_nodes) - len(match)/2\n",
    "\n",
    "    return B, match, num_taxi, trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifteen_min_B, fifteen_min_match, fifteen_min_vnum_taxi, fifteen_min_trips = max_match(1020, 1035, trips_df, 10)\n",
    "print('max cardinality matching:', len(fifteen_min_match)/2)\n",
    "print('min number of taxis needed to cover all trips:', fifteen_min_vnum_taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try expanding the time window to 5-6 pm and restricting the max waiting time to 5 mininutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below and change START_TIME, END_TIME, and MAX_WAIT_TIME.\n",
    "# one_hr_B, one_hr_match, one_hr_num_taxi, one_hr_trips =  max_match(START_TIME, END_TIME, trips_df, MAX_WAIT_TIME)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "one_hr_B, one_hr_match, one_hr_num_taxi, one_hr_trips = max_match(1020, 1080, trips_df, 5)\n",
    "### END SOLUTION\n",
    "print('max cardinality matching:', len(one_hr_match)/2)\n",
    "print('min number of taxis needed to cover all trips:', one_hr_num_taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Compare one day's taxi routing solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the result of a day's data with a max waiting time of 10 min\n",
    "with open('data/day_match.pkl', 'rb') as f:\n",
    "    match = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal taxi paths\n",
    "opt_paths = match_to_path(match, trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the street network\n",
    "G = street_network(nodes_df, arcs_df, weight = 'trip_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the routes with more than 1 trip\n",
    "opt_paths2 = []\n",
    "for path in opt_paths:\n",
    "    if len(path) > 1:\n",
    "        opt_paths2.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_taxi_route(G, opt_paths2[:5], nodes_df,'Optimal Sample Taxi Routes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the original paths of the taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_paths = get_og_path(trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the routes with more than 1 trip\n",
    "og_paths2 = []\n",
    "for path in og_paths:\n",
    "    if len(path) > 1:\n",
    "        og_paths2.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_taxi_route(G, og_paths2[:5], nodes_df,'Original Sample Taxi Routes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare statistics of the taxi routings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_stats = get_taxi_stats(opt_paths, trips_df)\n",
    "og_stats = get_taxi_stats(og_paths, trips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics for the original taxi routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stats(og_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics for the optimal taxi routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_stats(opt_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(og_stats, opt_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What conclusions can you draw from the histograms above in terms of the difference between the original and the optimal taxi routings?\n",
    "\n",
    "**A:** <font color='blue'> Total trip time and empty trip time are greatly reduced. However, to offset the reductions in trip time, the number of trips and on-trip percentage are increased.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to compare different taxi routings is to compare their distribution of taxis over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_data = get_day_dist(og_paths, opt_paths, times_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_taxi_dist(day_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What are the estimated original and optimal number of circulating taxis on this example day shown above?\n",
    "\n",
    "**A:** <font color='blue'> Original number of circulating taxis: 7798; optimal number of circulating taxis: 1305.  </font>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}