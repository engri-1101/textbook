{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from networkx.classes.function import path_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.read_csv('data/2013-09-01_trip_data_manhattan.csv').drop(columns='id')\n",
    "nodes_df = pd.read_csv('data/nyc_nodes_manhattan.csv').drop(columns='Unnamed: 0')\n",
    "arcs_df = pd.read_csv('data/nyc_links_manhattan.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the street network\n",
    "G = nx.Graph()\n",
    "for l in range(len(nodes_df)):\n",
    "    G.add_node(l)\n",
    "for index, row in arcs_df.iterrows():\n",
    "    i = row['start']\n",
    "    j = row['end']\n",
    "    G.add_edge(i, j, weight = row['trip_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(lat1,lon1,lat2,lon2):\n",
    "    '''Calculate the Euclidean distance between two locations.'''\n",
    "    R = 6371  # Radius of the earth in km\n",
    "    return R * np.sqrt((lon1 - lon2)**2 + (lat1 - lat2)**2) * np.pi / 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_pu_pair =[]\n",
    "for i in pd.unique(trips_df.end_node):\n",
    "    for j in pd.unique(trips_df.start_node):\n",
    "        do_pu_pair.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store the shortest path and travel time\n",
    "time_map = dict()\n",
    "shortest_paths = dict()\n",
    "for d,p in do_pu_pair:\n",
    "    try:\n",
    "        shortest_path = nx.shortest_path(G, source=d, target=p, weight = 'weight')\n",
    "        shortest_paths[(d, p)] = shortest_path\n",
    "        time_map[(d, p)] = int(path_weight(G, shortest_path, weight=\"weight\"))\n",
    "    # Use the straight-line distance to estimate travel time if there's no path in the street network\n",
    "    except nx.NetworkXNoPath:\n",
    "        time_map[(d, p)] = int(compute_distance(nodes_df.loc[d, 'lat'], nodes_df.loc[d, 'lon'],\n",
    "                                        nodes_df.loc[p, 'lat'], nodes_df.loc[p, 'lon']) / (30/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the distribution of travel time\n",
    "plt.hist(list(time_map.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df = pd.Series(time_map).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df.to_csv('data/times.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store the location-time dictionary in a pickel file\n",
    "# with open('data/time_map.pkl', 'wb') as f:\n",
    "#     pickle.dump(time_map, f)\n",
    "# with open('data/time_map.pkl', 'rb') as f:\n",
    "#     times = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one day's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the travel time matrix to a dictionary\n",
    "times = dict()\n",
    "for label, content in times_df.items():\n",
    "    for idx in content.index:\n",
    "        times[int(idx), int(label)] = content[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "def max_match(start_time, end_time, trips_df, max_waiting_time):\n",
    "    # filter trips by time window of interest\n",
    "    trips = trips_df.copy()\n",
    "    trips = trips[(trips.start_time >= start_time) & \n",
    "                  (trips.start_time + trips.trip_time <= end_time)].copy()\n",
    "    trips.start_time = trips.start_time - start_time\n",
    "\n",
    "    # create a dictionary to map the location pairs to trip time\n",
    "    loc_time = dict()\n",
    "    for index, row in arcs_df.iterrows():\n",
    "        i = row['start']\n",
    "        j = row['end']\n",
    "        delay = row['trip_time']\n",
    "        loc_time[(i, j)] = delay\n",
    "    # Intialize nodes and edges\n",
    "    DO_nodes = list()\n",
    "    PU_nodes = list()\n",
    "    edges = list()\n",
    "    # Initialize a dict that maps a PU node to a DO node\n",
    "    PUtoDO = dict()\n",
    "    # Specify nodes - each node is a tuple of (location_id, time, trip_id, \"DO\"/\"PU\")\n",
    "    for index, row in trips.iterrows():\n",
    "        s = row['start_node']\n",
    "        t = row['end_node']\n",
    "        s_t = row['start_time']\n",
    "        t_t = s_t + row['trip_time']\n",
    "        DO_node = (int(t), t_t, index, 'DO')\n",
    "        PU_node = (int(s), s_t, index, 'PU')\n",
    "        DO_nodes.append(DO_node)\n",
    "        PU_nodes.append(PU_node)\n",
    "        PUtoDO[PU_node] = DO_node\n",
    "    DO_nodes = sorted(DO_nodes, key = lambda x: x[1])\n",
    "    PU_nodes = sorted(PU_nodes, key = lambda x: x[1])\n",
    "    \n",
    "    # Specify edges\n",
    "    for DO_node in DO_nodes:\n",
    "        for PU_node in PU_nodes:\n",
    "            if PU_node[1] > DO_node[1] + max_waiting_time:\n",
    "                break\n",
    "            else:\n",
    "                if PU_node[1] >= DO_node[1]:\n",
    "                    time = times[(DO_node[0], PU_node[0])]\n",
    "                    if ((PU_node[1] - DO_node[1]) - max_waiting_time <= time) & (time <= (PU_node[1] - DO_node[1])):\n",
    "                        edges.append((DO_node, PU_node))\n",
    "    \n",
    "    # load the model\n",
    "    B = nx.Graph()\n",
    "    # Add nodes with the node attribute \"bipartite\"\n",
    "    B.add_nodes_from(DO_nodes, bipartite=0)\n",
    "    B.add_nodes_from(PU_nodes, bipartite=1)\n",
    "    # Add edges only between nodes of opposite node sets\n",
    "    B.add_edges_from(edges)\n",
    "    \n",
    "    top_nodes = {n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "    match = nx.bipartite.maximum_matching(B, top_nodes)\n",
    "\n",
    "    return match\n",
    "\n",
    "match = max_match(0, 1440, trips_df, 10)\n",
    "with open('data/day_match.pkl', 'wb') as f:\n",
    "    pickle.dump(match, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONT_SIZE = 15\n",
    "# # Total Trip Time\n",
    "# plt.rcParams.update({'font.size': FONT_SIZE})\n",
    "# fig, ax= plt.subplots(1,1, figsize=(8, 6))\n",
    "# plt.hist(og_total_time, label = 'Original', alpha = 0.8)\n",
    "# plt.hist(opt_total_time, color ='tab:red', label = 'Optimal', alpha = 0.7)\n",
    "# ax.set_xlabel('Total Trip Time (hr)')\n",
    "# ax.set_ylabel('Frequency')\n",
    "# min_ylim, max_ylim = plt.ylim()\n",
    "# plt.axvline(np.mean(og_total_time), color='blue', linestyle='dashed', linewidth=1)\n",
    "# plt.axvline(np.mean(opt_total_time), color='red', linestyle='dashed', linewidth=1)\n",
    "# ax.legend(loc=\"best\", prop={'size': FONT_SIZE});\n",
    "# # fig.savefig('visuals/total_trip_time.png', dpi = 1000, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total Empty Trip Time\n",
    "# plt.rcParams.update({'font.size': FONT_SIZE})\n",
    "# fig, ax= plt.subplots(1,1, figsize=(8, 6))\n",
    "# plt.hist(og_empty_time, label = 'Original')\n",
    "# plt.hist(opt_empty_time, color ='tab:red', label = 'Optimal')\n",
    "# ax.set_xlabel('Total Empty Trip Time (hr)')\n",
    "# ax.set_ylabel('Frequency')\n",
    "# ax.legend(loc=\"best\", prop={'size': FONT_SIZE});\n",
    "# # fig.savefig('visuals/empty_trip_time.png', dpi = 1000, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of Trips\n",
    "# plt.rcParams.update({'font.size': FONT_SIZE})\n",
    "# fig, ax= plt.subplots(1,1, figsize=(8, 6))\n",
    "# plt.hist(og_total_num_trips, label = 'Original')\n",
    "# plt.hist(opt_total_num_trips, color ='tab:red', label = 'Optimal')\n",
    "# ax.set_xlabel('Number of Trips')\n",
    "# ax.set_ylabel('Frequency')\n",
    "# ax.legend(loc=\"best\", prop={'size': FONT_SIZE});\n",
    "# fig.savefig('visuals/num_trip.png', dpi = 1000, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On-Trip Percentage\n",
    "# plt.rcParams.update({'font.size': FONT_SIZE})\n",
    "# fig, ax= plt.subplots(1,1, figsize=(8, 6))\n",
    "# plt.hist(np.array(og_on_trip) * 100 , label = 'Original')\n",
    "# plt.hist(np.array(opt_on_trip) * 100, color ='tab:red', label = 'Optimal')\n",
    "# ax.set_xlabel('Percent of Time A Taxi Was On A Trip')\n",
    "# ax.set_ylabel('Frequency')\n",
    "# ax.legend(loc=\"best\", prop={'size': FONT_SIZE});\n",
    "# fig.savefig('visuals/on_trip_pct.png', dpi = 1000, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
